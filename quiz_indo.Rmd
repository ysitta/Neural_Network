---
title: "Kuis Neural Network"
author: "Team Algoritma"
date: "6/6/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Kuis Neural Network

Kuis ini merupakan bagian dari proses penilaian *Algoritma Academy*. Selamat Anda telah menyelesaikan materi *Neural Network*! Kami akan melakukan penilaian berupa kuis untuk menguji materi yang sudah dipelajari. Pengerjaan Kuis diharapkan dapat dilakukan di dalam kelas, silakan hubungi tim instruktur kami jika Anda melewatkan kesempatan untuk mengambilnya di kelas.

Untuk menyelesaikan kuis ini, Anda perlu untuk membuat model klasifikasi untuk mengklafisikasikan kategori dari gambar produk fashion menggunakan algoritma Neural Network menggunakan framework `Keras` dengan langkah-langkah berikut:

# 1. Persiapan Data

Mari kita mulai pengalaman penerapan neural network kita dengan menyiapkan dataset sebagai langkah pertama. Anda akan menggunakan `fashionmnist` dataset. Data disimpan dengan format CSV di dalam folder (zip) `fashionmnist` di dalam materi kursus. Data terdiri dari satu set train dan test yang menyimpan gambar produk fashion berukuran 28 x 28 pixel untuk 10 kategori yang berbeda. Gunakan daftar istilah berikut untuk melabelkan target Anda:

```{r}
categories <- c("T-shirt", "Trouser", "Pullover", "Dress", 
    "Coat", "Sandal", "Shirt", "Sneaker", "Bag", "Boot")
```

## 1.1 Muat library dan data

Silakan muat package berikut:

```{r}
library(readr)
library(keras)
library(caret)
library(dplyr)
```

Pada tahap ini, silakan muat dan periksa data fashionmnist kita dan simpan data tersebut sebagai `fashion_train` dan `fashion_test`. Silakan gunakan fungsi `read_csv()` dari package `readr` untuk mempercepat pembacaan data.

```{r}
fashion_train <- read_csv(...)
fashion_test <- read_csv(...)
```

Periksa `fashion_train` data dengan menggunakan `head()`.

```{r}
# your code here
```

`fashion_train` terdiri dari 60000 observasi dan 785 variabel (1 target and 784 prediktor). Setiap prediktor merepresentasikan pixel dari gambar.

## 1.2 Konversi data ke dalam matriks

Data berisi nilai pixel yang disimpan dalam data frame. Namun, kita harus mengkonversi data menjadi matriks sebelum kita membuat sebuah model. Silahkan konversi data menjadi format matrix menggunakan fungsi `data.matrix()` dan simpan hasil konversi `fashion_train` sebagai `train_m` sedangkan `fashion_test` sebagai `test_m`.

```{r}
train_m <- data.matrix(...)
test_m <- data.matrix(...)
```

## 1.3 Cross Validation

Setelah itu, kita harus memisahkan prediktor dan target untuk data `train_m` dan `test_m`.

```{r}
# Predictor variables in `train_m`
train_x <-  ...

# Predictor variables in `test_m`
test_x <- ...

# Target variables in `train_m`
train_y <- ...

# Target variables in `test_m`
test_y <- ...

```

## 1.4 Persiapkan training dan testing (ubah menjadi array)

Selanjutnya, kita harus mengkonversi matriks prediktor ke dalam bentuk array. Silahkan gunakan `array_reshape(data, dim(data))` untuk mengkonversi data.

```{r}
train_x_array <- array_reshape(..., dim(...))
test_x_array <- array_reshape(..., dim(...))
```

## 1.5 Features scaling

Persiapan selanjutnya sebelum data siap untuk dimodelkan adalah feature scaling. Silahkan jawab pertanyaan di bawah ini terlebih dahulu.

___
1. Setelah data ubah ke bentuk array, masih ada satu tahapan pra-proses data yang perlu dilakukan. Jika kita inspeksi suatu gambar di dalam data train, kita akan melihat bahwa nilai pixel jatuh dalam rentang 0 sampai 255. Kemudian, apakah tujuan dari membagi nilai pada array tersebut dengan 225?
  - [ ] Mengkonversi rentang nilai yang sebelumnya 0 hingga 255 menjadi 0 hingga 1
  - [ ] Mengubah ukuran lebar (*width*) dan tinggi (*height*) gambar menjadi 1 dimensi, karena data merupakan 3D array (*images*, *width*, *height*)
  - [ ] Menormalisasi nilai yang sebelumnya 0 hingga 255 menjadi -1 hingga 1

*Referensi Opsi Bahasa Inggris:*
  - [ ] Convert the array value from 0 to 255 into 0 to 1
  - [ ] Reshape the width and height into single dimension since the data is a 3-d array (images, width, height)
  - [ ] Normalize the array from 0 to 255 into -1 to 1
___

Tahap selanjutnya adalah menskalakan nilai array (`train_x_array` dan `test_x_array`) dengan membaginya dengan 255.

```{r}
train_x.keras <- train_x_array/...
test_x.keras <- test_x_array/...
```

Kita juga perlu menerapkan *one-hot encoding* ke target variabel (`train_y`) menggunakan fungsi `to_categorical()` dari `Keras` dan disimpan sebagai objek `train_y.keras`.

```{r}
train_y.keras <- ...
```

# 2 Membuat Model Neural Network

Sebelum kita aplikasikan neural network ke dataset fashionmnist, mari kita periksa pemahaman kita terkait neural network dengan menjawab pertanyaan-pertanyaan di bawah ini:

___
2. Pernyataan di bawah adalah benar mengenai Neural Networks, **KECUALI**
  - [ ] Input layer adalah layer pertama dari Neural Network, jumlah neuronnya berdasarkan jumlah prediktor
  - [ ] Bobot awal untuk tiap neuron ditentukan secara acak
  - [ ] *Activation functions* tidak melakukan transformasi data
  - [ ] Neural network disebut sebagai deep learning bila memiliki lebih dari 1 hidden layer.

*Referensi Opsi Bahasa Inggris:*
  - [ ] Input layer is the first layer in Neural Network, the number of neurons depends on the predictor variable on the data
  - [ ] The initial weight  for each neuron is defined randomly
  - [ ] Activation functions are not doing any transformation to the data
  - [ ] The neural network is called deep learning when it has more than one hidden layer
___

___
3. Model neural network dibangun untuk mengoptimalkan (meminimalkan) error, error jenis apa pada kasus regresi yang kita minimalkan?
  - [ ] Binary Crossentropy
  - [ ] Mean Absolute Error
  - [ ] Neuron weight
___

## 2.1 Membuat sebuah model dasar menggunakan `keras_model_sequential()`

Untuk mengatur layer, kita harus membuat model dasar, yaitu model Sequential. Panggil fungsi `keras_model_sequential()`, dan gunakan operator *pipe* untuk membangun arsitektur model dari model dasar yang ada.

## 2.2 Membangun Arsitektur (menentukan layer, neuron, dan fungsi aktivasi)

Untuk membangun arsitektur tiap layer, kita akan membuat beberapa model dengan mengatur beberapa parameter. Sebelum membangun arsitekturnya, kita atur initializer untuk memastikan hasil yang kita dapat tidak akan berubah.

```{r}
RNGkind(sample.kind = "Rounding")
set.seed(100)
initializer <- initializer_random_normal(seed = 100)
```

Pertama, buat model (simpan dalam `model_init`) dengan mendefinisikan parameter-parameter di bawah ini:
- layer pertama berisi 32 nodes, fungsi aktivasi relu, 784 input shape
- layer kedua berisi 32 nodes, fungsi aktivasi relu
- layer ketiga berisi 10 nodes, fungsi aktivasi softmax

```{r}
model_init <- keras_model_sequential() %>% 
  layer_dense(units = ..., activation = "...", input_shape = c(...),
              kernel_initializer = initializer, bias_initializer = initializer) %>% 
  layer_dense(units = ..., activation = "...",
              kernel_initializer = initializer, bias_initializer = initializer) %>% 
  layer_dense(units = ..., activation = "...", 
              kernel_initializer = initializer, bias_initializer = initializer)
```

Kedua, buatlah sebuah model (simpan ke dalam `model_bigger`) dengan mendefinisikan parameter di bawah ini:
- layer pertama berisi 512 node, fungsi aktivasi relu, 784 input shape
- layer kedua berisi 512 node, fungsi aktivasi relu
- layer ketiga berisi 10 node, fungsi aktivasi softmax

```{r}
model_bigger <- keras_model_sequential() %>% 
  layer_dense(units = ..., activation = "...", input_shape = c(...),
              kernel_initializer = initializer, bias_initializer = initializer) %>% 
  layer_dense(units = ..., activation = "...",
              kernel_initializer = initializer, bias_initializer = initializer) %>% 
  layer_dense(units = ..., activation = "...", 
              kernel_initializer = initializer, bias_initializer = initializer)
```

Silahkan jawab pertanyaan di bawah ini.
___
4. Dalam membangun model arsitektur, kita atur beberapa unit parameter. Di bawah ini merupakan pertimbangan menggunakan angka-angka tersebut, **KECUALI** 
  - [ ] Pada layer pertama, digunakan input shape 784 sesuai jumlah prediktor 
  - [ ] Pada hidden dan output layer, digunakan sembarang angka genap
  - [ ] Pada output layer, digunakan angka 10 yang merupakan jumlah kategori data

*Referensi Opsi Bahasa Inggris:*
  - [ ] In the first layer, we use 784 input shape based on the number of our predictors
  - [ ] In the hidden and output layer, we use any even number
  - [ ] In the output layer, we use 10 that is the number of our categories
___

## 2.3 Membangun arsitektur (mendefinisi *cost function* dan *optimizer*)

Kita masih perlu melakukan beberapa pengaturan sebelum melatih `model_init` dan` model_bigger`. Kita harus menyusun model dengan mendefinisikan *loss function*, jenis *optimizer*, dan metrik evaluasi. Harap *compile* model dengan mengatur parameter berikut:
- categorical crossentropy sebagai loss function
- adam sebagai optimizer dengan learning rate 0.001
- gunakan *accuracy* sebagai metrik evaluasi

```{r}
model_init %>% 
  compile(loss = "...", 
          optimizer = ...(lr = ...), 
          metrics = "...")
```

```{r}
model_bigger %>% 
  compile(loss = "...", 
          optimizer = ...(lr = ...), 
          metrics = "...")
```

## 2.4 *Fitting model* di data train (mengatur epoch dan ukuran batch)

Pada tahap ini, kita fit model menggunakan `epoch = 10` dan `batch_size = 100` untuk `model_init` dan `model_bigger`. Silahkan simpan hasil fit model ke dalam obyek `history_init` dan `history_bigger`.

```{r}
history_init <- model_init %>%
  fit(train_x.keras, train_y.keras, epoch = ..., batch_size = ...)
```

```{r}
history_bigger <- model_bigger %>% 
  fit(train_x.keras, train_y.keras, epoch = ..., batch_size = ...)
```

___
5. Dalam fitting model di atas, kita atur `epoch = 10`, artinya ...
  - [ ] Model melakukan proses feed-forward - back propagation untuk seluruh batch sebanyak 10 kali
  - [ ] Model melakukan proses feed-forward - back propagation untuk 10 batch sebanyak 1 kali
  - [ ] Model membagi 1 batch menjadi 10 kelompok training data

*Referensi Opsi Bahasa Inggris:*
  - [ ] The model does the feed-forward - back-propagation for all batch 10 times
  - [ ] The model does the feed-forward - back-propagation for 10 batch 1 times
  - [ ] The model divides one batch into 10 groups of training data
___

# 3 Prediksi ke data test

Untuk mengevaluasi performa model terhadap data yang belum dilihat, kita akan memprediksi data test (`test_x.keras`) menggunakan model yang sudah dilatih. Silahkan prediksi menggunakan fungsi `predict_classes()` dari package `Keras` dan simpan sebagai `pred_init` dan `pred_bigger`.

```{r}
pred_init <- keras::predict_classes(object = ..., x= ...)

pred_bigger <- keras::predict_classes(object = ..., x= ...)
```

# 4 Evaluasi model neural network

Karena label masih bertipe dbl, maka silahkan decode label tersebut berdasarkan kategorinya. Jalankan code berikut untuk membuat fungsi `decode()`

```{r}
decode <- function(data){
  sapply(as.character(data), switch,
       "0" = "T-Shirt",
       "1" = "Trouser",
       "2" = "Pullover",
       "3" = "Dress",
       "4" = "Coat",
       "5" = "Sandal",
       "6" = "Shirt",
       "7" = "Sneaker",
       "8" = "Bag",
       "9" = "Boot")
}
```

*Decode* `pred_init` dan `pred_bigger` sebelum kita mengevaluasi performa model menggunakan confusion matrix. Anda juga perlu *decode* `test_y` untuk mendapatkan label sebenarnya dari variabel target.

```{r}
reference <- decode(test_y)
pred_decode_in <- decode(...)
pred_decode_big <- decode(...)
```

## 4.1 Confusion Matrix (klasifikasi)

Setelah melakukan *decode* variabel target, selanjutnya Anda dapat mengevaluasi model menggunakan beberapa *metrics*. Pada kuis ini, periksalah akurasi pada confusion matrix di bawah ini.

Note: jangan lupa untuk melakukan *explicit coercion* `as.factor` bila data Anda belum dalam bentuk faktor

```{r}
library(caret)
confusionMatrix(as.factor(...), as.factor(...))
confusionMatrix(as.factor(...), as.factor(...))
```

___  
6. Dari dua confusion matrix di atas, pernyataan di bawah yang paling sesuai adalah?
  - [ ] Semakin banyak neuron, performa model dapat meningkat karena semakin banyak features yang dapat diekstraksi dari data
  - [ ] Semakin sedikit neuron, performa model dapat meningkat karena semakin sedikit features tidak penting yang diekstraksi dari data
  - [ ] Jumlah neuron pada hidden layer tidak mempengaruhi performa model

*Referensi Opsi Bahasa Inggris:*
  - [ ] The more the neuron, the model may have better performance because more features will be extracted from the data
  - [ ] The less the neuron, the model may have better performance because less unnecessary features will be extracted from the data
  - [ ] The number of neuron in the hidden layer does not relate with the model performance
___
  
# 4.2 Model Tuning

Ternyata atasan kita ingin mendapatkan model terbaik, jadi dia meminta Anda untuk membuat satu model lagi sebagai pembanding (simpan sebagai `model_tuning`). Sekarang, mari kita coba membangun `model_tuning` dengan mengatur parameter sebagai berikut:
- menggunakan sgd sebagai optimizer dengan learning rate 0,001
- parameter lainnya sama dengan `model_init`

```{r}
model_tuning <- keras_model_sequential() %>% 
  layer_dense(units = ..., activation = "...", input_shape = c(...),
              kernel_initializer = initializer, bias_initializer = initializer) %>% 
  layer_dense(units = ..., activation = "...",
              kernel_initializer = initializer, bias_initializer = initializer) %>% 
  layer_dense(units = ..., activation = "...", 
              kernel_initializer = initializer, bias_initializer = initializer)

model_tuning %>% 
  compile(loss = "...", 
          optimizer = ...(lr = ...), 
          metrics = "...")

history_tuning <- model_tuning %>%
  fit(train_x.keras, train_y.keras, epoch = 10, batch_size = 100)
```

Setelah tuning model, silahkan prediksi `test_x.keras` menggunakan `model_tuning`.

```{r}
pred_tuning <- keras::predict_classes(object = ..., x= ...)
```

Kemudian, *decode* `pred_tuning` dan periksa performa model menggunakan `confusionMatrix()`.

```{r}
pred_decode_tun <- decode(...)
confusionMatrix(as.factor(...), as.factor(...))
```

Silahkan jawab pertanyaan di bawah ini.
___
7. Optimizer digunakan untuk meng-*update* bobot sehingga meminimalkan loss function. Apa yang dapat Anda simpulkan dari `model_init` dan `model_tuning` mengenai optimizer?
  - [ ] Optimizer Adam lebih baik dibandingkan Sgd
  - [ ] Optimizer Sgd lebih baik dibandingkan Adam
  - [ ] Kedua tipe optimizer tidak mempengaruhi performa model

*Referensi Opsi Bahasa Inggris:*
  - [ ] Optimizer Adam is more powerful than Sgd
  - [ ] Optimizer Sgd is more powerful than Adam
  - [ ] Both of the optimizers do not influence the model performance
___

___
8. Dari 3 model yang telah dibuat (`model_init`, `model_bigger` dan `model_tuning`), model mana yang terbaik untuk kita pilih?
  - [ ] model_tuning, karena performanya lebih tinggi dan akurasinya seimbang antara data train dan data test
  - [ ] model_init, karena performanya lebih tinggi dan akurasinya seimbang antara data train dan data test
  - [ ] model_bigger, karena performanya lebih tinggi dan akurasinya seimbang antara data train dan data test

*Referensi Opsi Bahasa Inggris:*
  - [ ] model_tuning, because the model has higher performance and balanced accuracy between train and test
  - [ ] model_init, because the model has higher performance and balanced accuracy between train and test
  - [ ] model_bigger, because the model has higher performance and balanced accuracy between train and test
  
*Note: untuk studi kasus ini, kita menganggap perbedaan poin akurasi 0.1 poin masih ditoleransi (cukup seimbang)*
___
